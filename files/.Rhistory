#UNICLUST_PATH = '/Users/januszkoszucki/hh-suite/databases/uniclust30_2018_08/uniclust30_2018_08'
# algorithm parameters
NO_CLASS_SYMBOL = "other" # this is what all proteins that could not be classified will be called
PROB_THRESHOLD = 80 # probability threshold for hhsuite. Only hits with probability higher than this thresholds will be considered as annotations
# path run in the bash profile
LOCAL_PATH = '/usr/local/bin:/usr/local/lib:/usr/bin:/bin:/usr/sbin:/sbin'
HHSUITE_PATH_FOR_BASH = '/Users/januszkoszucki/Programs/hh-suite/build/bin:/Users/januszkoszucki/Programs/hh-suite/'
HHSUITE_PATH='/Users/januszkoszucki/Programs/hh-suite/'
MULTIPHATE_PATH = "/Users/januszkoszucki/Programs/multiPhATE/"
PANNZER_PATH = '/Users/januszkoszucki/Programs/SANSPANZ.3/'
DROPBOX_PATH = "/Users/januszkoszucki/Programs/mostowylab/"
DROPBOX_PVOG_PATH = '/Users/januszkoszucki/MGG Dropbox/Databases/pvog-db/'
# path to this script
# some temporary scripts will be created here
#TMP_PATH = "/Users/januszkoszucki/Dropbox_Projects/PhageRBP-Mark-Data/preliminary-analyses/4_analysis-2020-01/"
TMP_PATH = "/Users/januszkoszucki/Dropbox_Projects/Janusz-Virsorter-Data/temp/"
# this is path to the working folder (intermediate inputs)
#WORKING_PATH = '/Users/januszkoszucki/Temp_Data/4_analysis-2020-01_new/'
WORKING_PATH = "/Users/januszkoszucki/Temp_Data/Janusz-2020-05/"
# FASTA FILE WITH ALL THE GENOMES WE WANT TO ANALYSE
GENOMES_FASTA_PATH = '/Users/januszkoszucki/Dropbox_Projects/Janusz-Virsorter-Data/virsorter_high_scores.fasta'
# Folder where the subfoldrrs for each genome will be created
#GENOMES_PATH = paste0(WORKING_PATH, 'RefSeq_sample/')
GENOMES_PATH = "/Users/januszkoszucki/Dropbox_Projects/Janusz-Virsorter-Data/Genomes/"
# folder in the working directory where the results will be saved
#WORKING_OUTPUT_PATH = paste0(WORKING_PATH, 'RefSeq_sample/')
WORKING_OUTPUT_PATH = paste0(WORKING_PATH, 'Virsorter_sample/')
# define where the final outputs will be saved
FINAL_OUTPUT_PATH = "/Users/januszkoszucki/Dropbox_Projects/Janusz-Virsorter-Data/output_data/"
# paths to HHSUITE DATABASES
SCOP_PATH = '/Users/januszkoszucki/Programs/hh-suite/databases/scop70_1.75'
PVOG_PATH = '/Users/januszkoszucki/Programs/hh-suite/databases/pvog/'
PFAM_PATH = '/Users/januszkoszucki/Programs/hh-suite/databases/pfam/'
PDB70_PATH = '/Users/januszkoszucki/Programs/hh-suite/databases/pdb70/'
#UNICLUST_PATH = '/Users/januszkoszucki/hh-suite/databases/uniclust30_2018_08/uniclust30_2018_08'
# algorithm parameters
NO_CLASS_SYMBOL = "other" # this is what all proteins that could not be classified will be called
PROB_THRESHOLD = 80 # probability threshold for hhsuite. Only hits with probability higher than this thresholds will be considered as annotations
# read in libraries
library(dplyr)
library(ape)
library(phytools)
library(seqinr)
library(stringr)
# library(qdap) # in case we want to do more text processing
# set local paths so that we can use the system() command: note some conda dependensies may not work
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
HHSUITE_PATH1 = paste0(HHSUITE_PATH_FOR_BASH, 'build/scripts')
HHSUITE_PATH2 = paste0(HHSUITE_PATH_FOR_BASH, 'build/bin')
#CONDA_PATH = "/Users/januszkoszucki/opt/miniconda3/envs/multiphate/bin"
Sys.setenv(PATH=paste(LOCAL_PATH, HHSUITE_PATH1, HHSUITE_PATH2, sep=":"))
# read in data on pvog names
pvogFunctionsMap = read.csv(paste0(DROPBOX_PVOG_PATH, "custom_data/protein_class_map_2020_02.csv"))
# source the helper functions needed for this pipeline
HELPER_FUNCTIONS_PATH = paste0(DROPBOX_PATH, "scripts/helpers/")
source(paste0(HELPER_FUNCTIONS_PATH, 'hhsuite.R'))
source(paste0(HELPER_FUNCTIONS_PATH, 'phanotate_helper.R'))
source(paste0(HELPER_FUNCTIONS_PATH, "local_helpers.R"))
# multiphate
TEMP_CONFIG_FILENAME = paste0("multiphate_config_tmp_", Sys.Date(),".config")
multiphate_input_dir = paste0(MULTIPHATE_PATH, "/PipelineInput/")
# this is a templetate to run Multiphate. Make sure you modify this file so that it includes appropriate paths to datasets
config_template_path = paste0(DROPBOX_PATH, "scripts/annotation_pipeline/multiphate_config_template_part2.txt")
# keywords used in annotation
protein_classes = Define_Protein_Classes_Data()
phage_main_classes = protein_classes$phage_main_classes
phage_protein_classes = protein_classes$phage_protein_classes
# databases
# customise those parameters if needed
DATABASES = c('scop' = SCOP_PATH,
'pfam' = PFAM_PATH,
'pvog' = PVOG_PATH,
'pdb70' = PDB70_PATH
#'uniclust' = UNICLUST_PATH
)
dir.create(TMP_PATH, recursive = TRUE)
dir.create(GENOMES_PATH)
Split_Fasta(fasta_sequences_path = GENOMES_FASTA_PATH,
split_fasta_files_dir = GENOMES_PATH,
prefix = NULL)
genome_names = dir(GENOMES_PATH, pattern = ".fasta")
for (genome_name in genome_names) {
folder.out = paste0(GENOMES_PATH, gsub(".fasta", "", genome_name, "/"))
dir.create(folder.out)
file.rename(from = paste0(GENOMES_PATH, genome_name),
to = paste0(folder.out, "/", genome_name))
}
genomes_names = list.dirs(GENOMES_PATH, full.names = FALSE, recursive = FALSE)
genomes_names = sort(genomes_names)
genome_names
# create multiphate config
# IN THIS VESRION OUR CNFIG ONLY WILL RUN BLAST vs PHANTOME
# PVOGS & HMMER ARE DISABLED AS WE WILL RUN HHSUITE ON PVOGS LATER
config_file = CreateMultiphateConfig(config_template_path, selected_genomes = genomes_names)
writeChar(config_file,  con = paste0(MULTIPHATE_PATH, "/", TEMP_CONFIG_FILENAME))
# RUN MULTIPHATE FOR PHANTOME DATA ONLY
# so we will create a temporary shell script and run the multiphate from that script
multiphateCommand = paste0("cd ", MULTIPHATE_PATH, "; python multiPhate.py ", TEMP_CONFIG_FILENAME)
writeChar(multiphateCommand,  con = paste0(TMP_PATH, "run-multiphate.sh"))
# can't activate conda from a script. So RUN THIS COMMAND MANUALLY IN TERMINAL
# make sure you turn on the environment in which multiphate works
# for me this is multiPhate conda env
system(command = paste0("conda activate multiPhate; sh ",TMP_PATH, "run-multiphate.sh"))
paste0("conda activate multiPhate; sh ",TMP_PATH, "run-multiphate.sh")
# RUN MULTIPHATE FOR PHANTOME DATA ONLY
# so we will create a temporary shell script and run the multiphate from that script
multiphateCommand = paste0("cd ", MULTIPHATE_PATH, "; python multiPhate.py ", TEMP_CONFIG_FILENAME)
writeChar(multiphateCommand,  con = paste0(TMP_PATH, "run-multiphate.sh"))
# can't activate conda from a script. So RUN THIS COMMAND MANUALLY IN TERMINAL
# make sure you turn on the environment in which multiphate works
# for me this is multiPhate conda env
system(command = paste0("conda activate multiPhate; sh ",TMP_PATH, "run-multiphate.sh"))
# Our files are already in .fasta so we just need to copy them
for (genomes_name in genomes_names) {
# convert to fasta (small case letters and save in multiohate)
file_path = paste0(GENOMES_PATH, genomes_name, "/", genomes_name, ".fasta")
out_path = paste0(multiphate_input_dir,  genomes_name, ".fasta")
file.copy(from = file_path, to = out_path)
}
# 3) copy the multiphate files to the analysis folder
dir.create(WORKING_OUTPUT_PATH)
# ------------------------------ COPY MULTIPHATE OUTPUTS TO OUR WORKING FOLDER --------------------------#
for (genome_name in genomes_names) {
genome_data_dir = paste0(MULTIPHATE_PATH, "/PipelineOutput/",genome_name ,"/")
output_dir = paste0(WORKING_OUTPUT_PATH, genome_name)
dir.create(output_dir)
copyResultsCommand = paste0(
"cp -r ", genome_data_dir, "phate_sequenceAnnotation_main.gff ", output_dir, "; ",
"cp -r ", genome_data_dir, "protein.faa ", output_dir, "; "
#"cp -r ", genome_data_dir, genome_name,  ".config ", output_dir, "; "
)
system(command = copyResultsCommand)
}
WORKING_OUTPUT_PATH
# for all names create protein.fasta instead of protein.fa so that it can be then used for PANNZER
for (genome_name in genomes_names) {
fasta_file = read.fasta(paste0(WORKING_OUTPUT_PATH, genome_name, "/", 'protein.faa'))
write.fasta(sequences = fasta_file, names = names(fasta_file),
file.out = paste0(WORKING_OUTPUT_PATH, genome_name, "/", 'protein.fasta'),
open = "w")
file.remove(paste0(WORKING_OUTPUT_PATH, genome_name, "/", 'protein.faa'))
}
for (genome_name in genomes_names) {
genome_data_dir = paste0(WORKING_OUTPUT_PATH, genome_name, "/")
genome_data_separate_fasta_dir = paste0(genome_data_dir,  "fasta_files")
# create directory for the separate gene fasta files. results will be saved here
dir.create(genome_data_separate_fasta_dir, recursive = FALSE)
# split "protein.faa" that contains many gene fasta seq and save the all of them in the results file
fasta_sequences_path = paste0(genome_data_dir, "protein.fasta")
Split_Fasta(fasta_sequences_path = fasta_sequences_path,
split_fasta_files_dir = genome_data_separate_fasta_dir,
prefix = NA)
}
# 5) -------- RUN HHSUITE USING MULTIPHATE OUTPUTS (protein.faa)  -----------------------#
#<we could also use phanotate results here. they are the same so it is fine
for (genome_name in genomes_names) {
genome_data_dir = paste0(WORKING_OUTPUT_PATH,"/",genome_name , "/")
genome_data_separate_fasta_dir = paste0(genome_data_dir,  "fasta_files/")
# do that on every database we have available in hhsuite
for (j in 1:length(DATABASES)) {
thisDB = DATABASES[j]
print(paste0("ANALYSING ",genome_name, ', database: ', names(thisDB)))
database_name = as.character(thisDB)
genome_data_separate_hhr_dir = paste0(genome_data_dir,  "hhr_files/", names(thisDB), "/")
filename = paste0("_", names(thisDB), '.txt')
## run hhsuite on the splitted fasta files
#file.names = dir(genome_data_separate_fasta_dir, pattern =".fasta")
#for (file in file.names) {
#  Run_HHsuite(database_name, file, paste0(gsub('.fasta', '', file), filename), genome_data_separate_fasta_dir)
#}
#alternative to the code above: write shell code that will do the work for us
# make sure in the script we use the params we want
SCRIPTS_PATH = paste0(DROPBOX_PATH, "scripts/annotation_pipeline/")
system(command =paste0(" sh ", SCRIPTS_PATH, "run_hhblits_parallel.sh SCRIPTS_PATH='",SCRIPTS_PATH ,
"' DATABASE_PATH='", database_name,
"' INPUT_PATH='", genome_data_separate_fasta_dir,
"' OUTPUT_PATH='", paste0(genome_data_separate_hhr_dir, "'")))
}
# after the script is run for all databases we can move the outputs to the fasta folder
for (j in 1:length(DATABASES)) {
thisDB = DATABASES[j]
database_name = as.character(thisDB)
genome_data_separate_hhr_dir = paste0(genome_data_dir,  "hhr_files/", names(thisDB), "/")
filename = paste0("_", names(thisDB), '.txt')
old_names = dir(genome_data_separate_hhr_dir, full.names = FALSE)
new_names = paste0(gsub(".hhr","", old_names), filename)
file.copy(from = paste0(genome_data_separate_hhr_dir, old_names),
to =  paste0(genome_data_separate_fasta_dir, new_names))
}
}
# path run in the bash profile
LOCAL_PATH = '/usr/local/bin:/usr/local/lib:/usr/bin:/bin:/usr/sbin:/sbin'
HHSUITE_PATH_FOR_BASH = '/Users/januszkoszucki/Programs/hh-suite/build/bin:/Users/januszkoszucki/Programs/hh-suite/'
HHSUITE_PATH='/Users/januszkoszucki/Programs/hh-suite/'
MULTIPHATE_PATH = "/Users/januszkoszucki/Programs/multiPhATE/"
PANNZER_PATH = '/Users/januszkoszucki/Programs/SANSPANZ.3/'
DROPBOX_PATH = "/Users/januszkoszucki/Programs/mostowylab/"
DROPBOX_PVOG_PATH = '/Users/januszkoszucki/MGG Dropbox/Databases/pvog-db/'
# path to this script
# some temporary scripts will be created here
#TMP_PATH = "/Users/januszkoszucki/Dropbox_Projects/PhageRBP-Mark-Data/preliminary-analyses/4_analysis-2020-01/"
TMP_PATH = "/Users/januszkoszucki/Dropbox_Projects/Janusz-Virsorter-Data/temp/"
# this is path to the working folder (intermediate inputs)
#WORKING_PATH = '/Users/januszkoszucki/Temp_Data/4_analysis-2020-01_new/'
WORKING_PATH = "/Users/januszkoszucki/Temp_Data/Janusz-2020-05/"
# FASTA FILE WITH ALL THE GENOMES WE WANT TO ANALYSE
GENOMES_FASTA_PATH = '/Users/januszkoszucki/Dropbox_Projects/Janusz-Virsorter-Data/virsorter_high_scores.fasta'
# Folder where the subfoldrrs for each genome will be created
#GENOMES_PATH = paste0(WORKING_PATH, 'RefSeq_sample/')
GENOMES_PATH = "/Users/januszkoszucki/Dropbox_Projects/Janusz-Virsorter-Data/Genomes/"
# folder in the working directory where the results will be saved
#WORKING_OUTPUT_PATH = paste0(WORKING_PATH, 'RefSeq_sample/')
WORKING_OUTPUT_PATH = paste0(WORKING_PATH, 'Virsorter_sample/')
# define where the final outputs will be saved
FINAL_OUTPUT_PATH = "/Users/januszkoszucki/Dropbox_Projects/Janusz-Virsorter-Data/output_data/"
# paths to HHSUITE DATABASES
SCOP_PATH = '/Users/januszkoszucki/Programs/hh-suite/databases/scop70_1.75'
PVOG_PATH = '/Users/januszkoszucki/Programs/hh-suite/databases/pvog/pvog'
PFAM_PATH = '/Users/januszkoszucki/Programs/hh-suite/databases/pfam/pfam'
PDB70_PATH = '/Users/januszkoszucki/Programs/hh-suite/databases/pdb70/'
#UNICLUST_PATH = '/Users/januszkoszucki/hh-suite/databases/uniclust30_2018_08/uniclust30_2018_08'
# algorithm parameters
NO_CLASS_SYMBOL = "other" # this is what all proteins that could not be classified will be called
PROB_THRESHOLD = 80 # probability threshold for hhsuite. Only hits with probability higher than this thresholds will be considered as annotations
# 5) -------- RUN HHSUITE USING MULTIPHATE OUTPUTS (protein.faa)  -----------------------#
#<we could also use phanotate results here. they are the same so it is fine
for (genome_name in genomes_names) {
genome_data_dir = paste0(WORKING_OUTPUT_PATH,"/",genome_name , "/")
genome_data_separate_fasta_dir = paste0(genome_data_dir,  "fasta_files/")
# do that on every database we have available in hhsuite
for (j in 1:length(DATABASES)) {
thisDB = DATABASES[j]
print(paste0("ANALYSING ",genome_name, ', database: ', names(thisDB)))
database_name = as.character(thisDB)
genome_data_separate_hhr_dir = paste0(genome_data_dir,  "hhr_files/", names(thisDB), "/")
filename = paste0("_", names(thisDB), '.txt')
## run hhsuite on the splitted fasta files
#file.names = dir(genome_data_separate_fasta_dir, pattern =".fasta")
#for (file in file.names) {
#  Run_HHsuite(database_name, file, paste0(gsub('.fasta', '', file), filename), genome_data_separate_fasta_dir)
#}
#alternative to the code above: write shell code that will do the work for us
# make sure in the script we use the params we want
SCRIPTS_PATH = paste0(DROPBOX_PATH, "scripts/annotation_pipeline/")
system(command =paste0(" sh ", SCRIPTS_PATH, "run_hhblits_parallel.sh SCRIPTS_PATH='",SCRIPTS_PATH ,
"' DATABASE_PATH='", database_name,
"' INPUT_PATH='", genome_data_separate_fasta_dir,
"' OUTPUT_PATH='", paste0(genome_data_separate_hhr_dir, "'")))
}
# after the script is run for all databases we can move the outputs to the fasta folder
for (j in 1:length(DATABASES)) {
thisDB = DATABASES[j]
database_name = as.character(thisDB)
genome_data_separate_hhr_dir = paste0(genome_data_dir,  "hhr_files/", names(thisDB), "/")
filename = paste0("_", names(thisDB), '.txt')
old_names = dir(genome_data_separate_hhr_dir, full.names = FALSE)
new_names = paste0(gsub(".hhr","", old_names), filename)
file.copy(from = paste0(genome_data_separate_hhr_dir, old_names),
to =  paste0(genome_data_separate_fasta_dir, new_names))
}
}
PVOG_PATH
PVOG_PATH
DATABASES
j=1
thisDB = DATABASES[j]
print(paste0("ANALYSING ",genome_name, ', database: ', names(thisDB)))
database_name = as.character(thisDB)
genome_data_separate_hhr_dir = paste0(genome_data_dir,  "hhr_files/", names(thisDB), "/")
filename = paste0("_", names(thisDB), '.txt')
## run hhsuite on the splitted fasta files
#file.names = dir(genome_data_separate_fasta_dir, pattern =".fasta")
#for (file in file.names) {
#  Run_HHsuite(database_name, file, paste0(gsub('.fasta', '', file), filename), genome_data_separate_fasta_dir)
#}
#alternative to the code above: write shell code that will do the work for us
# make sure in the script we use the params we want
SCRIPTS_PATH = paste0(DROPBOX_PATH, "scripts/annotation_pipeline/")
system(command =paste0(" sh ", SCRIPTS_PATH, "run_hhblits_parallel.sh SCRIPTS_PATH='",SCRIPTS_PATH ,
"' DATABASE_PATH='", database_name,
"' INPUT_PATH='", genome_data_separate_fasta_dir,
"' OUTPUT_PATH='", paste0(genome_data_separate_hhr_dir, "'")))
# path run in the bash profile
LOCAL_PATH = '/usr/local/bin:/usr/local/lib:/usr/bin:/bin:/usr/sbin:/sbin'
HHSUITE_PATH_FOR_BASH = '/Users/januszkoszucki/Programs/hh-suite/build/bin:/Users/januszkoszucki/Programs/hh-suite/'
HHSUITE_PATH='/Users/januszkoszucki/Programs/hh-suite/'
MULTIPHATE_PATH = "/Users/januszkoszucki/Programs/multiPhATE/"
PANNZER_PATH = '/Users/januszkoszucki/Programs/SANSPANZ.3/'
DROPBOX_PATH = "/Users/januszkoszucki/Programs/mostowylab/"
DROPBOX_PVOG_PATH = '/Users/januszkoszucki/MGG Dropbox/Databases/pvog-db/'
# path to this script
# some temporary scripts will be created here
#TMP_PATH = "/Users/januszkoszucki/Dropbox_Projects/PhageRBP-Mark-Data/preliminary-analyses/4_analysis-2020-01/"
TMP_PATH = "/Users/januszkoszucki/Dropbox_Projects/Janusz-Virsorter-Data/temp/"
# this is path to the working folder (intermediate inputs)
#WORKING_PATH = '/Users/januszkoszucki/Temp_Data/4_analysis-2020-01_new/'
WORKING_PATH = "/Users/januszkoszucki/Temp_Data/Janusz-2020-05/"
# FASTA FILE WITH ALL THE GENOMES WE WANT TO ANALYSE
GENOMES_FASTA_PATH = '/Users/januszkoszucki/Dropbox_Projects/Janusz-Virsorter-Data/virsorter_high_scores.fasta'
# Folder where the subfoldrrs for each genome will be created
#GENOMES_PATH = paste0(WORKING_PATH, 'RefSeq_sample/')
GENOMES_PATH = "/Users/januszkoszucki/Dropbox_Projects/Janusz-Virsorter-Data/Genomes/"
# folder in the working directory where the results will be saved
#WORKING_OUTPUT_PATH = paste0(WORKING_PATH, 'RefSeq_sample/')
WORKING_OUTPUT_PATH = paste0(WORKING_PATH, 'Virsorter_sample/')
# define where the final outputs will be saved
FINAL_OUTPUT_PATH = "/Users/januszkoszucki/Dropbox_Projects/Janusz-Virsorter-Data/output_data/"
# paths to HHSUITE DATABASES
SCOP_PATH = '/Users/januszkoszucki/Programs/hh-suite/databases/scop70_1.75/scop70_1.75'
PVOG_PATH = '/Users/januszkoszucki/Programs/hh-suite/databases/pvog/pvog'
PFAM_PATH = '/Users/januszkoszucki/Programs/hh-suite/databases/pfam/pfam'
PDB70_PATH = '/Users/januszkoszucki/Programs/hh-suite/databases/pdb70/'
#UNICLUST_PATH = '/Users/januszkoszucki/hh-suite/databases/uniclust30_2018_08/uniclust30_2018_08'
# algorithm parameters
NO_CLASS_SYMBOL = "other" # this is what all proteins that could not be classified will be called
PROB_THRESHOLD = 80 # probability threshold for hhsuite. Only hits with probability higher than this thresholds will be considered as annotations
SCOP_PATH
thisDB = DATABASES[j]
print(paste0("ANALYSING ",genome_name, ', database: ', names(thisDB)))
database_name = as.character(thisDB)
genome_data_separate_hhr_dir = paste0(genome_data_dir,  "hhr_files/", names(thisDB), "/")
filename = paste0("_", names(thisDB), '.txt')
## run hhsuite on the splitted fasta files
#file.names = dir(genome_data_separate_fasta_dir, pattern =".fasta")
#for (file in file.names) {
#  Run_HHsuite(database_name, file, paste0(gsub('.fasta', '', file), filename), genome_data_separate_fasta_dir)
#}
#alternative to the code above: write shell code that will do the work for us
# make sure in the script we use the params we want
SCRIPTS_PATH = paste0(DROPBOX_PATH, "scripts/annotation_pipeline/")
system(command =paste0(" sh ", SCRIPTS_PATH, "run_hhblits_parallel.sh SCRIPTS_PATH='",SCRIPTS_PATH ,
"' DATABASE_PATH='", database_name,
"' INPUT_PATH='", genome_data_separate_fasta_dir,
"' OUTPUT_PATH='", paste0(genome_data_separate_hhr_dir, "'")))
thisDB
# path run in the bash profile
LOCAL_PATH = '/usr/local/bin:/usr/local/lib:/usr/bin:/bin:/usr/sbin:/sbin'
HHSUITE_PATH_FOR_BASH = '/Users/januszkoszucki/Programs/hh-suite/build/bin:/Users/januszkoszucki/Programs/hh-suite/'
HHSUITE_PATH='/Users/januszkoszucki/Programs/hh-suite/'
MULTIPHATE_PATH = "/Users/januszkoszucki/Programs/multiPhATE/"
PANNZER_PATH = '/Users/januszkoszucki/Programs/SANSPANZ.3/'
DROPBOX_PATH = "/Users/januszkoszucki/Programs/mostowylab/"
DROPBOX_PVOG_PATH = '/Users/januszkoszucki/MGG Dropbox/Databases/pvog-db/'
# path to this script
# some temporary scripts will be created here
#TMP_PATH = "/Users/januszkoszucki/Dropbox_Projects/PhageRBP-Mark-Data/preliminary-analyses/4_analysis-2020-01/"
TMP_PATH = "/Users/januszkoszucki/Dropbox_Projects/Janusz-Virsorter-Data/temp/"
# this is path to the working folder (intermediate inputs)
#WORKING_PATH = '/Users/januszkoszucki/Temp_Data/4_analysis-2020-01_new/'
WORKING_PATH = "/Users/januszkoszucki/Temp_Data/Janusz-2020-05/"
# FASTA FILE WITH ALL THE GENOMES WE WANT TO ANALYSE
GENOMES_FASTA_PATH = '/Users/januszkoszucki/Dropbox_Projects/Janusz-Virsorter-Data/virsorter_high_scores.fasta'
# Folder where the subfoldrrs for each genome will be created
#GENOMES_PATH = paste0(WORKING_PATH, 'RefSeq_sample/')
GENOMES_PATH = "/Users/januszkoszucki/Dropbox_Projects/Janusz-Virsorter-Data/Genomes/"
# folder in the working directory where the results will be saved
#WORKING_OUTPUT_PATH = paste0(WORKING_PATH, 'RefSeq_sample/')
WORKING_OUTPUT_PATH = paste0(WORKING_PATH, 'Virsorter_sample/')
# define where the final outputs will be saved
FINAL_OUTPUT_PATH = "/Users/januszkoszucki/Dropbox_Projects/Janusz-Virsorter-Data/output_data/"
# paths to HHSUITE DATABASES
SCOP_PATH = '/Users/januszkoszucki/Programs/hh-suite/databases/scop70_1.75/scop70_1.75'
PVOG_PATH = '/Users/januszkoszucki/Programs/hh-suite/databases/pvog/pvog'
PFAM_PATH = '/Users/januszkoszucki/Programs/hh-suite/databases/pfam/pfam'
PDB70_PATH = '/Users/januszkoszucki/Programs/hh-suite/databases/pdb70/'
#UNICLUST_PATH = '/Users/januszkoszucki/hh-suite/databases/uniclust30_2018_08/uniclust30_2018_08'
# algorithm parameters
NO_CLASS_SYMBOL = "other" # this is what all proteins that could not be classified will be called
PROB_THRESHOLD = 80 # probability threshold for hhsuite. Only hits with probability higher than this thresholds will be considered as annotations
SCOP_PATH
dir.create(GENOMES_PATH)
Split_Fasta(fasta_sequences_path = GENOMES_FASTA_PATH,
split_fasta_files_dir = GENOMES_PATH,
prefix = NULL)
genome_names = dir(GENOMES_PATH, pattern = ".fasta")
for (genome_name in genome_names) {
folder.out = paste0(GENOMES_PATH, gsub(".fasta", "", genome_name, "/"))
dir.create(folder.out)
file.rename(from = paste0(GENOMES_PATH, genome_name),
to = paste0(folder.out, "/", genome_name))
}
# read in libraries
library(dplyr)
library(ape)
library(phytools)
library(seqinr)
library(stringr)
# library(qdap) # in case we want to do more text processing
# set local paths so that we can use the system() command: note some conda dependensies may not work
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
HHSUITE_PATH1 = paste0(HHSUITE_PATH_FOR_BASH, 'build/scripts')
HHSUITE_PATH2 = paste0(HHSUITE_PATH_FOR_BASH, 'build/bin')
#CONDA_PATH = "/Users/januszkoszucki/opt/miniconda3/envs/multiphate/bin"
Sys.setenv(PATH=paste(LOCAL_PATH, HHSUITE_PATH1, HHSUITE_PATH2, sep=":"))
# read in data on pvog names
pvogFunctionsMap = read.csv(paste0(DROPBOX_PVOG_PATH, "custom_data/protein_class_map_2020_02.csv"))
# source the helper functions needed for this pipeline
HELPER_FUNCTIONS_PATH = paste0(DROPBOX_PATH, "scripts/helpers/")
source(paste0(HELPER_FUNCTIONS_PATH, 'hhsuite.R'))
source(paste0(HELPER_FUNCTIONS_PATH, 'phanotate_helper.R'))
source(paste0(HELPER_FUNCTIONS_PATH, "local_helpers.R"))
# multiphate
TEMP_CONFIG_FILENAME = paste0("multiphate_config_tmp_", Sys.Date(),".config")
multiphate_input_dir = paste0(MULTIPHATE_PATH, "/PipelineInput/")
# this is a templetate to run Multiphate. Make sure you modify this file so that it includes appropriate paths to datasets
config_template_path = paste0(DROPBOX_PATH, "scripts/annotation_pipeline/multiphate_config_template_part2.txt")
# keywords used in annotation
protein_classes = Define_Protein_Classes_Data()
phage_main_classes = protein_classes$phage_main_classes
phage_protein_classes = protein_classes$phage_protein_classes
# databases
# customise those parameters if needed
DATABASES = c('scop' = SCOP_PATH,
'pfam' = PFAM_PATH,
'pvog' = PVOG_PATH,
'pdb70' = PDB70_PATH
#'uniclust' = UNICLUST_PATH
)
dir.create(TMP_PATH, recursive = TRUE)
# 5) -------- RUN HHSUITE USING MULTIPHATE OUTPUTS (protein.faa)  -----------------------#
#<we could also use phanotate results here. they are the same so it is fine
for (genome_name in genomes_names) {
genome_data_dir = paste0(WORKING_OUTPUT_PATH,"/",genome_name , "/")
genome_data_separate_fasta_dir = paste0(genome_data_dir,  "fasta_files/")
# do that on every database we have available in hhsuite
for (j in 1:length(DATABASES)) {
thisDB = DATABASES[j]
print(paste0("ANALYSING ",genome_name, ', database: ', names(thisDB)))
database_name = as.character(thisDB)
genome_data_separate_hhr_dir = paste0(genome_data_dir,  "hhr_files/", names(thisDB), "/")
filename = paste0("_", names(thisDB), '.txt')
## run hhsuite on the splitted fasta files
#file.names = dir(genome_data_separate_fasta_dir, pattern =".fasta")
#for (file in file.names) {
#  Run_HHsuite(database_name, file, paste0(gsub('.fasta', '', file), filename), genome_data_separate_fasta_dir)
#}
#alternative to the code above: write shell code that will do the work for us
# make sure in the script we use the params we want
SCRIPTS_PATH = paste0(DROPBOX_PATH, "scripts/annotation_pipeline/")
system(command =paste0(" sh ", SCRIPTS_PATH, "run_hhblits_parallel.sh SCRIPTS_PATH='",SCRIPTS_PATH ,
"' DATABASE_PATH='", database_name,
"' INPUT_PATH='", genome_data_separate_fasta_dir,
"' OUTPUT_PATH='", paste0(genome_data_separate_hhr_dir, "'")))
}
# after the script is run for all databases we can move the outputs to the fasta folder
for (j in 1:length(DATABASES)) {
thisDB = DATABASES[j]
database_name = as.character(thisDB)
genome_data_separate_hhr_dir = paste0(genome_data_dir,  "hhr_files/", names(thisDB), "/")
filename = paste0("_", names(thisDB), '.txt')
old_names = dir(genome_data_separate_hhr_dir, full.names = FALSE)
new_names = paste0(gsub(".hhr","", old_names), filename)
file.copy(from = paste0(genome_data_separate_hhr_dir, old_names),
to =  paste0(genome_data_separate_fasta_dir, new_names))
}
}
command = ""
for (genome_name in genomes_names) {
input_fasta_file = paste0(WORKING_OUTPUT_PATH, genome_name, "/", 'protein.fasta')
out_folder = paste0(WORKING_OUTPUT_PATH, genome_name)
file_our_name = genome_name
dir.create(paste0(out_folder,"/pannzer_output"))
# The last output is the summary of the annotation that is then converted to HTML
# we should use that one. Note however that sometimes thos functions may have a bit simplified names
out_names = ",,,pannzer_output/anno.out"
# the forth argument will give the functions
new_command = paste0('cd ', out_folder, '; python ', PANNZER_PATH,  'runsanspanz.py -R -o "',out_names, '" -s "Klebsiella phage" -i ', input_fasta_file)
#cat(new_command)
command = paste(command, new_command ,sep = "; ")
}
writeLines(command, paste0(TMP_PATH, "run_pannzer_tmp.sh"))
paste0('conda activate multiphate; sh ', TMP_PATH, 'run_pannzer_tmp.sh')
# create a function like read.hhr but different
PPV_THRESHOLD = 0.7
for (genome_name in genomes_names) {
out_folder = paste0(WORKING_OUTPUT_PATH, genome_name)
file_our_name = genome_name
panzeer_output_path = paste0(out_folder, "/pannzer_output/")
result = ReadPanzeerResults(panzeer_output_path, PPV_THRESHOLD,
func = FALSE, go = FALSE, de = FALSE)
write.csv(result, paste0(out_folder, "/pannzer_results_simplified.csv"))
}
#genomes_names = setdiff(genomes_names, "GCF_002149205.1_ViralProj266637.3_genomic")
geneFromFileNameFunction = function(file.name, db) {
str1 = strsplit(file.name, "_phanotate_")[[1]][2]
str2 =  strsplit(str1, '_geneCall_')[[1]][1]
return(str2)
}
# if there are no panzeer outputs set panzeer_output_path to NULL
for (genome_nr in 1:length(genomes_names)) {
genome_name = genomes_names[genome_nr]
genome_data_dir = paste0(WORKING_OUTPUT_PATH, genomes_names[genome_nr] , "/")
genome_data_separate_fasta_dir = paste0(genome_data_dir, "fasta_files")
all_data = Analyse_Piepline_Results(multiphate_output_path = genome_data_dir,
path_to_pipeline_output = genome_data_separate_fasta_dir,
panzeer_output_path = NULL,#paste0(genome_data_dir,"pannzer_results_simplified.csv"),
genome_name = genome_name,
database_list = DATABASES,
pvogFunctionsMap = pvogFunctionsMap,
geneFromFileNameFunction = geneFromFileNameFunction,
gffName = "phate_sequenceAnnotation_main.gff")
write.csv(all_data, file = paste0(genome_data_dir, "gene_annotations_automatic.csv"), row.names = FALSE)
}
for (genome_nr in seq_len(length(genomes_names))) {
temp_dir = paste0(WORKING_OUTPUT_PATH,  genomes_names[genome_nr], "/")
# compress all teh fasta files folder; we will store it as a backup
system(paste0('cd ',temp_dir, '; tar czf fasta_files.tar.gz fasta_files'))
output_dir = paste0(FINAL_OUTPUT_PATH, '/', genomes_names[genome_nr] ,"/")
dir.create(output_dir, recursive = TRUE)
copyResultsCommand = paste0(
"cp -r ", temp_dir, "protein.fasta ", output_dir, "; "#,
"cp -r ", temp_dir, genomes_names[genome_nr],  ".config ", output_dir, "; ",
